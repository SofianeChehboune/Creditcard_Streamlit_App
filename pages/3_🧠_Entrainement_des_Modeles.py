
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go
from imblearn.over_sampling import SMOTE
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import numpy as np

st.set_page_config(page_title="Entra√Ænement des Mod√®les", layout="wide", page_icon="üß†")

st.title("3. Entra√Ænement et √âvaluation des Mod√®les")
st.markdown("Cette page vous permet d'entra√Æner plusieurs mod√®les de classification et de comparer leurs performances.")

# --- 1. Chargement des Donn√©es Pr√©par√©es ---
st.header("1. Chargement des Donn√©es Pr√©par√©es")

# V√©rifier si les donn√©es ont √©t√© pr√©par√©es
if 'data_prepared' not in st.session_state:
    st.warning("Les donn√©es n'ont pas √©t√© pr√©par√©es. Veuillez d'abord vous rendre sur la page 'üõ†Ô∏è Pr√©paration des Donn√©es'.")
    st.stop()

st.success("Donn√©es pr√©par√©es charg√©es avec succ√®s depuis la page pr√©c√©dente.")

# Charger les donn√©es depuis st.session_state
prepared_data = st.session_state['data_prepared']
X_train = prepared_data['X_train']
X_test = prepared_data['X_test']
y_train = prepared_data['y_train']
y_test = prepared_data['y_test']
amount_scaler = prepared_data['amount_scaler']
time_scaler = prepared_data['time_scaler']

use_smote = st.checkbox("Utiliser SMOTE pour corriger le d√©s√©quilibre des classes ?")
if use_smote:
    st.info("SMOTE (Synthetic Minority Over-sampling Technique) va √™tre appliqu√© sur les donn√©es d'entra√Ænement pour g√©n√©rer des √©chantillons synth√©tiques de la classe minoritaire (fraude).")

# --- 2. Model Selection and Training ---
st.header("2. S√©lection et Entra√Ænement des Mod√®les")

model_options = ['R√©gression Logistique', 'Arbre de D√©cision', 'For√™t Al√©atoire', 'Gradient Boosting']
selected_models = st.multiselect("Choisissez les mod√®les √† entra√Æner", model_options, default=['R√©gression Logistique', 'For√™t Al√©atoire'])

@st.cache_resource
def get_model(model_name):
    models = {
        'R√©gression Logistique': LogisticRegression(random_state=42, max_iter=1000),
        'Arbre de D√©cision': DecisionTreeClassifier(random_state=42),
        'For√™t Al√©atoire': RandomForestClassifier(random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(random_state=42)
    }
    return models[model_name]

def plot_roc_curve(y_true, y_proba):
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)
    fig = go.Figure(data=go.Scatter(x=fpr, y=tpr, mode='lines', name=f'Courbe ROC (AUC = {roc_auc:.2f})'))
    fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
    fig.update_layout(title_text="<b>Courbe ROC</b>", xaxis_title="Taux de Faux Positifs", yaxis_title="Taux de Vrais Positifs")
    return fig

def plot_feature_importance(model, feature_names):
    importances = model.feature_importances_
    indices = np.argsort(importances)[-15:]
    fig = px.bar(x=importances[indices], y=[feature_names[i] for i in indices], orientation='h',
                 title="<b>Top 15 des Caract√©ristiques les plus Importantes</b>", labels={'x': 'Importance', 'y': 'Caract√©ristique'})
    return fig

if st.button("Lancer l'entra√Ænement et l'√©valuation"):
    if 'trained_artifacts' not in st.session_state:
        st.session_state['trained_artifacts'] = {}

    X_train_processed = X_train.copy()
    y_train_processed = y_train.copy()

    if use_smote:
        with st.spinner("Application de SMOTE..."):
            smote = SMOTE(random_state=42)
            X_train_processed, y_train_processed = smote.fit_resample(X_train, y_train)
            st.success(f"SMOTE appliqu√©. Nouvelles dimensions de l'ensemble d'entra√Ænement : {X_train_processed.shape}")

    for model_name in selected_models:
        st.subheader(f"R√©sultats pour : {model_name}")
        model = get_model(model_name)

        with st.spinner(f"Entra√Ænement du mod√®le {model_name}..."):
            model.fit(X_train_processed, y_train_processed)
            st.session_state['trained_artifacts'][model_name] = {'model': model, 'amount_scaler': amount_scaler, 'time_scaler': time_scaler}
            y_pred = model.predict(X_test)
            y_proba = model.predict_proba(X_test)[:, 1]

            # --- 3. Evaluation ---
            st.markdown("#### √âvaluation du Mod√®le")
            col1, col2 = st.columns(2)

            with col1:
                report = classification_report(y_test, y_pred, target_names=['Non-Fraude', 'Fraude'], output_dict=True)
                st.write("<b>Rapport de Classification</b>", unsafe_allow_html=True)
                st.dataframe(pd.DataFrame(report).transpose())

            with col2:
                cm = confusion_matrix(y_test, y_pred)
                fig_cm = ff.create_annotated_heatmap(cm[::-1], x=['Non-Fraude', 'Fraude'], y=['Fraude', 'Non-Fraude'][::-1], colorscale='Blues')
                fig_cm.update_layout(title_text="<b>Matrice de Confusion</b>", xaxis_title="Pr√©diction", yaxis_title="Vrai")
                st.plotly_chart(fig_cm, use_container_width=True)

            col3, col4 = st.columns(2)
            with col3:
                st.plotly_chart(plot_roc_curve(y_test, y_proba), use_container_width=True)

            with col4:
                if hasattr(model, 'feature_importances_'):
                    st.plotly_chart(plot_feature_importance(model, X_test.columns), use_container_width=True)
                else:
                    st.info("Ce mod√®le ne fournit pas d'importance pour les caract√©ristiques.")

        st.success(f"Le mod√®le **{model_name}** a √©t√© entra√Æn√© et est disponible sur la page 'üîÆ Pr√©diction' !")
        st.markdown("---")
